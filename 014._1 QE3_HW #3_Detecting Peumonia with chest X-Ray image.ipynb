{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, zipfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipfile processing\n",
    "# data_zip_dir = '/datasets/chest_xray/chest_xray.zip'        # for VM Machine\n",
    "data_zip_dir = '/Users/hsyoon/Desktop/ANN/chest_xray.zip' # for Local Machine\n",
    "data_dir = './datasets/'\n",
    "\n",
    "# init\n",
    "if os.path.isdir(os.path.join(data_dir, 'chest_xray')):\n",
    "    pass\n",
    "else:\n",
    "    shutil.rmtree(data_dir)\n",
    "    with zipfile.ZipFile(data_zip_dir, 'r') as z:\n",
    "        z.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasetDir(data_dir):\n",
    "    train_dir = os.path.join(data_dir, 'chest_xray', 'train')\n",
    "    val_dir = os.path.join(data_dir, 'chest_xray', 'val')\n",
    "    test_dir = os.path.join(data_dir, 'chest_xray', 'test')\n",
    "    return train_dir, val_dir, test_dir\n",
    "\n",
    "def getResultDir(dataset_dir):\n",
    "    normal_dir = os.path.join(data_dir, 'NORMAL')\n",
    "    pneumonia_dir = os.path.join(data_dir, 'PNEUMONIA')\n",
    "    return normal_dir, pneumonia_dir\n",
    "\n",
    "def dataGenerator(resolution:tuple, batch_size:int):\n",
    "    # set image generators\n",
    "    (train_dir, val_dir, test_dir) = getDatasetDir(data_dir)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=20, shear_range=0.1,\n",
    "                                    width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                    zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            target_size=resolution,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            target_size=resolution,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=resolution,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    return train_generator, validation_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_1():\n",
    "    # # vgg16 input size\n",
    "    # input_shape = (224, 224, 3)\n",
    "    # InceptionV3 input size\n",
    "    input_shape = (299, 299, 3)\n",
    "\n",
    "    # base_model = VGG16(weights='imagenet', input_shape=input_shape, include_top=False)\n",
    "    base_model = InceptionV3(weights='imagenet', input_shape=input_shape, include_top=False)\n",
    "\n",
    "    base_model.trainable = False     # freezing model\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    y = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=y)\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def unfreeze_model(model):\n",
    "    for layer in model.layers:\n",
    "        if layer.name.startswith('block5'):\n",
    "            layer.trainable = True\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "                    loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# w/ Dropout Layer\n",
    "def build_model_2():\n",
    "    # # vgg16 input size\n",
    "    # input_shape = (224, 224, 3)\n",
    "    # InceptionV3 input size\n",
    "    input_shape = (299, 299, 3)\n",
    "\n",
    "    # base_model = VGG16(weights='imagenet', input_shape=input_shape, include_top=False)\n",
    "    base_model = InceptionV3(weights='imagenet', input_shape=input_shape, include_top=False)\n",
    "    \n",
    "    base_model.trainable = False     # freezing model\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    y = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=y)\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_acc_loss(h):\n",
    "    plt.figure(figsize=(15.6, 4.8), dpi=100)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    plt.plot(h.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (128, 128)\n",
    "(train_generator, val_generator, test_generator) = dataGenerator(resolution, batch_size=20)\n",
    "\n",
    "# training before FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "model = build_model_1()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs,\n",
    "                              validation_data=val_generator)\n",
    "print(\"1st learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution before FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_1_beforeFT.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (Before FT):', train_acc)\n",
    "print('test_acc (Before FT):', test_acc)\n",
    "print('train_loss (Before FT):', train_loss)\n",
    "print('test_loss (Before FT):', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and unfreezing pre-trained model\n",
    "model = models.load_model('./qe3_1_beforeFT.h5')\n",
    "unfreeze_model(model)\n",
    "\n",
    "# training after FT\n",
    "num_epochs = 50\n",
    "starttime=time.time()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"2nd learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution after FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_1_afterFT.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (After FT):', train_acc)\n",
    "print('test_acc: (After FT)', test_acc)\n",
    "print('train_loss (After FT):', train_loss)\n",
    "print('test_loss: (After FT)', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training before FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "model = build_model_2()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"1st learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution before FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_2_beforeFT.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (Before FT):', train_acc)\n",
    "print('test_acc (Before FT):', test_acc)\n",
    "print('train_loss (Before FT):', train_loss)\n",
    "print('test_loss (Before FT):', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and unfreezing pre-trained model\n",
    "model = models.load_model('./qe3_2_beforeFT.h5')\n",
    "unfreeze_model(model)\n",
    "\n",
    "# training after FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"2nd learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution after FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_2_afterFT.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (After FT):', train_acc)\n",
    "print('test_acc: (After FT)', test_acc)\n",
    "print('train_loss (After FT):', train_loss)\n",
    "print('test_loss: (After FT)', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for [256, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (256, 256)\n",
    "(train_generator, val_generator, test_generator) = dataGenerator(resolution, batch_size=20)\n",
    "\n",
    "# training before FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "model = build_model_2() # w/ dropout layer\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"1st learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution before FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_3_beforeFT_256.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (Before FT):', train_acc)\n",
    "print('test_acc (Before FT):', test_acc)\n",
    "print('train_loss (Before FT):', train_loss)\n",
    "print('test_loss (Before FT):', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and unfreezing pre-trained model\n",
    "model = models.load_model('./qe3_3_beforeFT_256.h5')\n",
    "unfreeze_model(model)\n",
    "\n",
    "# training after FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"2nd learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution after FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_3_afterFT_256.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (After FT):', train_acc)\n",
    "print('test_acc: (After FT)', test_acc)\n",
    "print('train_loss (After FT):', train_loss)\n",
    "print('test_loss: (After FT)', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for [512, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = (512, 512)\n",
    "(train_generator, val_generator, test_generator) = dataGenerator(resolution, batch_size=10)\n",
    "\n",
    "# training before FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "model = build_model_2() # w/ dropout layer\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"1st learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution before FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_3_beforeFT_512.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (Before FT):', train_acc)\n",
    "print('test_acc (Before FT):', test_acc)\n",
    "print('train_loss (Before FT):', train_loss)\n",
    "print('test_loss (Before FT):', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and unfreezing pre-trained model\n",
    "model = models.load_model('./qe3_3_beforeFT_512.h5')\n",
    "unfreeze_model(model)\n",
    "\n",
    "# training after FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"2nd learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution after FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_3_afterFT_512.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (After FT):', train_acc)\n",
    "print('test_acc: (After FT)', test_acc)\n",
    "print('train_loss (After FT):', train_loss)\n",
    "print('test_loss: (After FT)', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.preprocessing import image \n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\t\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(X):\n",
    "    X = (X - X.mean()) / (X.std() + 1e-5)       # normalize\n",
    "    X = 0.1 * X + 0.5                           # scaling\n",
    "    X = np.clip(X, 0, 1)                        # clipping\n",
    "    X = (X * 255).clip(0, 255).astype('uint8')  # type change/clipping\n",
    "    return X \n",
    "\n",
    "\n",
    "def draw_activation(activation, figure_name):\n",
    "    images_per_row = 16\n",
    "    n_features = activation.shape[-1]\n",
    "    size = activation.shape[1]\n",
    "    n_cols=n_features // images_per_row\n",
    "    display_grid=np.zeros((size * n_cols, images_per_row*size))\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = activation[0, :, :, col*images_per_row+row]\n",
    "            channel_image = deprocess_image(channel_image)\n",
    "            display_grid[col*size:(col+1)*size,\n",
    "            row*size:(row+1)*size] = channel_image\n",
    "    scale = 1./size\n",
    "\n",
    "    plt.figure(figsize=(scale*display_grid.shape[1], scale*display_grid.shape[0])) \n",
    "    plt.title(figure_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "    plt.show()\n",
    "\n",
    "def gradCAM(model, x):\n",
    "    preds = model.predict(x)\n",
    "    print('Predicted:', decode_predictions(preds, top=5)[0])\n",
    "    max_output=model.output[:,np.argmax(preds)]\n",
    "    \n",
    "    # last_conv_layer = model.get_layer('block5_conv3')   # for VGG16\n",
    "    last_conv_layer = model.get_layer('mixed10')      # for InceptionV3\n",
    "\n",
    "    # grads = K.gradients(max_output, last_conv_layer.output)[0]  # (None, 14, 14, 512) for VGG16\n",
    "    grads = K.gradients(max_output, last_conv_layer.output)[0]  # (None, 17, 17, 2048) for InceptionV3\n",
    "\n",
    "    # gradient of max_output with respect to last_conv_layer.output\n",
    "    pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "    \n",
    "    iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "    pooled_grads_value, conv_layer_output_value=iterate([x])\n",
    "    \n",
    "    for i in range(2048):    # the number of filters (InceptionV3 : 2048)\n",
    "        conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "    heatmap = np.mean(conv_layer_output_value, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) \n",
    "    heatmap /= np.max(heatmap) \n",
    "    return heatmap, conv_layer_output_value, pooled_grads_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocessing \n",
    "img_path = './datasets/chest_xray/train/PNEUMONIA/person1017_bacteria_2948.jpeg'\n",
    "img=image.load_img(img_path, target_size=(299,299)) \n",
    "img_tensor = image.img_to_array(img) \n",
    "img_tensor = np.expand_dims(img_tensor, axis=0) \n",
    "img_tensor = preprocess_input(img_tensor)\n",
    "\n",
    "# prediction \n",
    "model = InceptionV3(weights='imagenet') \n",
    "heatmap, conv_output, pooled_grads=gradCAM(model, img_tensor)\n",
    "\n",
    "# image processing\n",
    "img=cv2.imread(img_path)\n",
    "heatmap=cv2.resize(heatmap, (img.shape[1],img.shape[0]))\n",
    "heatmap=cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "# superimposed_image = cv2.addWeighted(original_image, 0.6, heatmap, 0.4, 0)\n",
    "superimposed_img=heatmap*0.4+img*0.6\n",
    "\n",
    "# save image\n",
    "cv2.imwrite(img_path.split('/')[-1].split('.')[0] + '_CAM.jpg', superimposed_img)\n",
    "\n",
    "\n",
    "# # visualization of conv_output and pooled_grads\n",
    "# draw_no=range(256,256+32,1)\n",
    "# conv_activation=np.expand_dims(conv_output[:,:,draw_no], axis=0)\n",
    "# draw_activation(conv_activation, 'last_conv')\n",
    "# plt.matshow(pooled_grads[draw_no].reshape(-1,16), cmap='viridis')\n",
    "\n",
    "# 8-bit processing to print image\n",
    "superimposed_img = cv2.cvtColor(np.uint8(superimposed_img), cv2.COLOR_BGR2RGB)\n",
    "# heatmap = cv2.cvtColor(np.uint8(heatmap), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax1.imshow(img / 255.0)\n",
    "ax1.set_title('Original Image')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(heatmap)\n",
    "ax2.set_title('Class Activation Map')\n",
    "ax2.axis('off')\n",
    "ax3.imshow(superimposed_img / 255.0)\n",
    "ax3.set_title('Original Image with CAM')\n",
    "ax3.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QE1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator_noSize(batch_size:int):\n",
    "    # set image generators\n",
    "    (train_dir, val_dir, test_dir) = getDatasetDir(data_dir)\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=20, shear_range=0.1,\n",
    "                                    width_shift_range=0.1, height_shift_range=0.1,\n",
    "                                    zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "            train_dir,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            val_dir,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            batch_size=batch_size,\n",
    "            class_mode='binary')\n",
    "    return train_generator, validation_generator, test_generator\n",
    "\n",
    "\n",
    "# w/ Dropout Layer\n",
    "def build_model_2_noSize():\n",
    "    # vgg16 input size\n",
    "    input_shape = (None, None, 3)\n",
    "\n",
    "    # include_top=False : excepting output Dense layer of vgg16 for matching an input layer dimension of GlobalAveragePooling2D\n",
    "    base_model = InceptionV3(weights='imagenet', input_shape=input_shape, include_top=False)\n",
    "    \n",
    "    base_model.trainable = False     # freezing model\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    y = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=y)\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_generator, val_generator, test_generator) = dataGenerator_noSize(batch_size=20)\n",
    "\n",
    "# training before FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "model = build_model_2_noSize() # w/ dropout layer\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"1st learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution before FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_e1_beforeFT_nosize.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (Before FT):', train_acc)\n",
    "print('test_acc (Before FT):', test_acc)\n",
    "print('train_loss (Before FT):', train_loss)\n",
    "print('test_loss (Before FT):', test_loss)\n",
    "\n",
    "# Loading and unfreezing pre-trained model\n",
    "model = models.load_model('./qe3_e1_beforeFT_nosize.h5')\n",
    "unfreeze_model(model)\n",
    "\n",
    "# training after FT\n",
    "num_epochs = 100\n",
    "starttime=time.time()\n",
    "history = model.fit_generator(train_generator, epochs=num_epochs, validation_data=val_generator)\n",
    "print(\"2nd learning elapsed time (in sec): \", time.time()-starttime)\n",
    "\n",
    "# evalution after FT\n",
    "model.summary()\n",
    "plot_acc_loss(history)\n",
    "model.save('./qe3_e1_afterFT_nosize.h5')\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print('train_acc (After FT):', train_acc)\n",
    "print('test_acc: (After FT)', test_acc)\n",
    "print('train_loss (After FT):', train_loss)\n",
    "print('test_loss: (After FT)', test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScore(model_dir:str):\n",
    "    test_generator = None\n",
    "    model = models.load_model(model_dir)\n",
    "    # q1, q2\n",
    "    if '128' in model_dir:\n",
    "        test_generator = dataGenerator((128, 128), batch_size=20)[2]\n",
    "    # q3_256\n",
    "    elif '256' in model_dir:\n",
    "        test_generator = dataGenerator((256, 256), batch_size=20)[2]\n",
    "    # q3_512\n",
    "    elif '512' in model_dir:\n",
    "        test_generator = dataGenerator((512, 512), batch_size=10)[2]\n",
    "    # qe1 (nosize)\n",
    "    elif 'nosize' in model_dir:\n",
    "        test_generator = dataGenerator_noSize(batch_size=20)[2]\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    y_true = test_generator.classes\n",
    "    y_pred = model.predict_generator(test_generator)\n",
    "    preds_1d = y_pred.flatten()\n",
    "    y_pred = np.where(preds_1d >= 0.5, 1, 0)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tp = cm[1, 1]\n",
    "\n",
    "    accuracy = (tn + tp) / (tn + fp + fn + tp)\n",
    "    precision = tp / (fp + tp)\n",
    "    recall = tp / (fn + tp)\n",
    "    specificity = tn / (tn + fp)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    plotCM(cm, y_pred, y_true)\n",
    "    print('<' + model_dir[:-3] + ' Score>')\n",
    "    print(f'Accuracy : {accuracy:.4f}')\n",
    "    print(f'Precision : {precision:.4f}')\n",
    "    print(f'Recall : {recall:.4f}')\n",
    "    print(f'Specificity : {specificity:.4f}')\n",
    "    print(f'F1 Score : {f1:.4f}')\n",
    "    print(f'AUC : {auc:.4f}')\n",
    "\n",
    "def plotCM(cm, y_pred, y_true):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "getScore('qe3_1_beforeFT_128.h5')\n",
    "getScore('qe3_1_afterFT_128.h5')\n",
    "getScore('qe3_2_beforeFT_128.h5')\n",
    "getScore('qe3_2_afterFT_128.h5')\n",
    "getScore('qe3_3_beforeFT_256.h5')\n",
    "getScore('qe3_3_afterFT_256.h5')\n",
    "getScore('qe3_3_beforeFT_512.h5')\n",
    "getScore('qe3_3_afterFT_512.h5')\n",
    "getScore('qe3_e1_beforeFT_nosize.h5')\n",
    "getScore('qe3_e1_afterFT_nosize.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
