{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, zipfile\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipfile processing\n",
    "data_zip_dir = '/datasets/dogs-vs-cats/dogs-vs-cats.zip'\n",
    "data_dir = './datasets/dogs-vs-cats'\n",
    "\n",
    "if os.path.isdir(os.path.join(data_dir)):\n",
    "    pass\n",
    "else:\n",
    "    with zipfile.ZipFile(data_zip_dir, 'r') as z:\n",
    "        z.extractall(data_dir)\n",
    "        \n",
    "\n",
    "train_zip_dir = os.path.join(data_dir, 'train.zip')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "with zipfile.ZipFile(train_zip_dir, 'r') as z:\n",
    "    z.extractall(data_dir)\n",
    "\n",
    "# test_zip_dir = os.path.join(data_dir, 'test1.zip')\n",
    "# test_dir = os.path.join(data_dir, 'test1')\n",
    "# with zipfile.ZipFile(test_zip_dir, 'r') as z:\n",
    "#     z.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset directory makeing func\n",
    "def make_dataset_dir(new_data_dir = './datasets/dogs-vs-cats_preparared'):\n",
    "    os.makedirs(new_data_dir, exist_ok=True)\n",
    "\n",
    "    # train\n",
    "    train_set_dir = os.path.join(new_data_dir, 'train_set')\n",
    "    train_dog_dir = os.path.join(train_set_dir, 'dog')\n",
    "    train_cat_dir = os.path.join(train_set_dir, 'cat')\n",
    "    os.makedirs(train_dog_dir, exist_ok=True)\n",
    "    os.makedirs(train_cat_dir, exist_ok=True)\n",
    "\n",
    "    # valid\n",
    "    valid_set_dir = os.path.join(new_data_dir, 'valid_set')\n",
    "    valid_dog_dir = os.path.join(valid_set_dir, 'dog')\n",
    "    valid_cat_dir = os.path.join(valid_set_dir, 'cat')\n",
    "    os.makedirs(valid_dog_dir, exist_ok=True)\n",
    "    os.makedirs(valid_cat_dir, exist_ok=True)\n",
    "\n",
    "    # test\n",
    "    test_set_dir = os.path.join(new_data_dir, 'test_set')\n",
    "    test_dog_dir = os.path.join(test_set_dir, 'dog')\n",
    "    test_cat_dir = os.path.join(test_set_dir, 'cat')\n",
    "    os.makedirs(test_dog_dir, exist_ok=True)\n",
    "    os.makedirs(test_cat_dir, exist_ok=True)\n",
    "    return train_set_dir, train_dog_dir, train_cat_dir, \\\n",
    "            valid_set_dir, valid_dog_dir, valid_cat_dir, \\\n",
    "            test_set_dir, test_dog_dir, test_cat_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_dir = './datasets/dogs-vs-cats_preparared'\n",
    "data_dir = './datasets/dogs-vs-cats'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "# init\n",
    "if os.path.isdir(new_data_dir):\n",
    "    shutil.rmtree(new_data_dir)\n",
    "(train_set_dir, train_dog_dir, train_cat_dir, \\\n",
    " valid_set_dir, valid_dog_dir, valid_cat_dir, \\\n",
    "    test_set_dir, test_dog_dir, test_cat_dir) = make_dataset_dir()\n",
    "\n",
    "# image file names list\n",
    "dog_files = [f'dog.{i}.jpg' for i in range(12500)]\n",
    "cat_files = [f'cat.{i}.jpg' for i in range(12500)]\n",
    " \n",
    "# move images to new_data dir\n",
    "train = 2000\n",
    "valid = 1000\n",
    "test = 1000\n",
    "\n",
    "if train+valid+test > 25000:\n",
    "    raise Exception('out of datasets')\n",
    "\n",
    "for file in dog_files[:int(train/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(train_dog_dir, file)\n",
    "    shutil.copy(src, dst)\n",
    "    \n",
    "for file in dog_files[int(train/2):int(train/2)+int(valid/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(valid_dog_dir, file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "for file in dog_files[int(train/2)+int(valid/2):int(train/2)+int(valid/2)+int(test/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(test_dog_dir, file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "for file in cat_files[:int(train/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(train_cat_dir, file)\n",
    "    shutil.copy(src, dst)\n",
    "    \n",
    "for file in cat_files[int(train/2):int(train/2)+int(valid/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(valid_cat_dir, file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "for file in cat_files[int(train/2)+int(valid/2):int(train/2)+int(valid/2)+int(test/2)]:\n",
    "    src = os.path.join(train_dir, file)\n",
    "    dst = os.path.join(test_cat_dir, file)\n",
    "    shutil.copy(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# of train set : {len(os.listdir(train_dog_dir)) + len(os.listdir(train_cat_dir))}')\n",
    "print(f'# of valid set : {len(os.listdir(valid_dog_dir)) + len(os.listdir(valid_cat_dir))}')\n",
    "print(f'# of test set : {len(os.listdir(test_dog_dir)) + len(os.listdir(test_cat_dir))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set image generators\n",
    "train_dir = train_set_dir\n",
    "validation_dir = valid_set_dir\n",
    "test_dir = test_set_dir\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                    rotation_range=20, shear_range=0.1,\n",
    "                    width_shift_range=0.1, height_shift_range=0.1,\n",
    "                    zoom_range=0.1, horizontal_flip=True, fill_mode='nearest')\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "input_shape = [150, 150, 3] # as a shape of image\n",
    "def build_model():\n",
    "    model=models.Sequential()\n",
    "    # conv_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    conv_base.trainable=False\n",
    "    model.add(conv_base)\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    # compile\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# main loop without cross-validation\n",
    "import time\n",
    "starttime=time.time()\n",
    "num_epochs = 30\n",
    "model = build_model()\n",
    "history = model.fit_generator(train_generator,\n",
    "                    epochs=num_epochs, steps_per_epoch=100,\n",
    "                    validation_data=validation_generator, validation_steps=50)\n",
    "\n",
    "# saving the model\n",
    "model.save('cats_and_dogs_small_pretrained.h5')\n",
    "\n",
    "# evaluation\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('train_acc:', train_acc)\n",
    "print('test_acc:', test_acc)\n",
    "print(\"elapsed time (in sec): \", time.time()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "def plot_acc_loss(h):\n",
    "    plt.figure(figsize=(15.6, 4.8), dpi=100)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    plt.plot(h.history['val_accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training', 'Validation'], loc=0)\n",
    "    plt.show()\n",
    "\n",
    "model.summary()\n",
    "plot_acc_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreezing func\n",
    "def unfreeze_model(model):\n",
    "    for layer in model.layers[249:]:\n",
    "        layer.trainable = True\n",
    "    model.compile(optimizer=optimizers.RMSprop(learning_rate=1e-5),\n",
    "                    loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "unfreeze_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop without cross-validation\n",
    "import time\n",
    "starttime=time.time()\n",
    "num_epochs = 50\n",
    "model = models.load_model('./cats_and_dogs_small_pretrained.h5')\n",
    "history = model.fit_generator(train_generator,\n",
    "                    epochs=num_epochs, steps_per_epoch=100,\n",
    "                    validation_data=validation_generator, validation_steps=50)\n",
    "\n",
    "# saving the model\n",
    "model.save('cats_and_dogs_small_finetuned.h5')\n",
    "\n",
    "# evaluation\n",
    "train_loss, train_acc = model.evaluate_generator(train_generator)\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print('train_acc:', train_acc)\n",
    "print('test_acc:', test_acc)\n",
    "print(\"elapsed time (in sec): \", time.time()-starttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_acc_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
